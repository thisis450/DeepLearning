{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "sys.path.append(\"BasicResNet\")\n",
    "from basic_tools import *\n",
    "from resnet_models import *\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x1 and 512x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32me:\\深度学习\\大作业\\DeepLearning\\test.ipynb 单元格 2\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/DeepLearning/test.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m features \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mavg_pool(input_image)  \u001b[39m# 获取最后一个卷积层的特征图\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/DeepLearning/test.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m weights \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfc\u001b[39m.\u001b[39mweight  \u001b[39m# 获取模型的权重\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/DeepLearning/test.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m cam \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(torch\u001b[39m.\u001b[39;49mmatmul(features, weights\u001b[39m.\u001b[39;49mT))  \u001b[39m# 使用CAM公式计算热力图\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/DeepLearning/test.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m cam \u001b[39m=\u001b[39m cam\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mnumpy()  \u001b[39m# 去除批次维度，并转换为NumPy数组\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/DeepLearning/test.ipynb#W5sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m cam \u001b[39m=\u001b[39m cam \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmin(cam)  \u001b[39m# 将热力图归一化到0-1范围\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x1 and 512x100)"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pdb\n",
    "from IC_DenseNet161 import densenet161\n",
    "\n",
    "# input image\n",
    "image_path = './data/test/0050/5755.jpg'\n",
    "\n",
    "# networks such as googlenet, resnet, densenet already use global average pooling at the end, so CAM could be used directly.\n",
    "\n",
    "net = densenet161()\n",
    "finalconv_name = 'features'\n",
    "\n",
    "net.eval()\n",
    "\n",
    "# hook the feature extractor\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "\n",
    "net._modules.get(finalconv_name).register_forward_hook(hook_feature)\n",
    "\n",
    "# get the softmax weight\n",
    "# 倒数第二层\n",
    "params = list(net.parameters())\n",
    "weight_softmax = np.squeeze(params[-2].data.numpy())\n",
    "\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (224, 224)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        # 回到GAP的值\n",
    "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        # np.min 返回数组的最小值或沿轴的最小值。\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        #  np.uint8(） Create a data type object.\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   # transforms.Resize((224,224)),\n",
    "   transforms.ToTensor(),\n",
    "   # normalize\n",
    "])\n",
    "\n",
    "image_path = os.path.expanduser(image_path)\n",
    "img_pil = Image.open(image_path)\n",
    "img_pil.save('test.jpg')\n",
    "\n",
    "img_tensor = preprocess(img_pil)\n",
    "img_variable = Variable(img_tensor.unsqueeze(0))\n",
    "logit = net(img_variable)\n",
    "\n",
    "h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "probs, idx = h_x.sort(0, True)\n",
    "probs = probs.numpy()\n",
    "idx = idx.numpy()\n",
    "\n",
    "# generate class activation mapping for the top1 prediction\n",
    "CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0]])\n",
    "\n",
    "# render the CAM and output\n",
    "# print('output CAM.jpg for the top1 prediction: %s'%classes[idx[0]])\n",
    "print('output CAM.jpg ')\n",
    "img = cv2.imread('./CAM/test.jpg')\n",
    "height, width, _ = img.shape\n",
    "heatmap = cv2.applyColorMap(cv2.resize(CAMs[0],(width, height)), cv2.COLORMAP_JET)\n",
    "result = heatmap * 0.3 + img * 0.5\n",
    "cv2.imwrite('./CAM/CAM.jpg', result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
