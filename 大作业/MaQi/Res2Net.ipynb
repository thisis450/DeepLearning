{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c938b7-b5e0-4285-8752-4ddd9f8b25d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from basic_tools import *\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14647aad-2dac-4bae-94bc-a4cd91412b47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, groups=groups, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb402026-fdd8-4f09-a668-e77de21e7257",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1, padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.avg_pool(input)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return input * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f0bbb9-0a09-45aa-8545-e9f870fb608c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Res2NetBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, downsample=None, stride=1, scales=4, groups=1, se=False,  norm_layer=None):\n",
    "        super(Res2NetBottleneck, self).__init__()\n",
    "        if planes % scales != 0:\n",
    "            raise ValueError('Planes must be divisible by scales')\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        bottleneck_planes = groups * planes\n",
    "        self.conv1 = conv1x1(inplanes, bottleneck_planes, stride)\n",
    "        self.bn1 = norm_layer(bottleneck_planes)\n",
    "        self.conv2 = nn.ModuleList([conv3x3(bottleneck_planes // scales, bottleneck_planes // scales, groups=groups) for _ in range(scales-1)])\n",
    "        self.bn2 = nn.ModuleList([norm_layer(bottleneck_planes // scales) for _ in range(scales-1)])\n",
    "        self.conv3 = conv1x1(bottleneck_planes, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se = SEModule(planes * self.expansion) if se else None\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.scales = scales\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        xs = torch.chunk(out, self.scales, 1)\n",
    "        ys = []\n",
    "        for s in range(self.scales):\n",
    "            if s == 0:\n",
    "                ys.append(xs[s])\n",
    "            elif s == 1:\n",
    "                ys.append(self.relu(self.bn2[s-1](self.conv2[s-1](xs[s]))))\n",
    "            else:\n",
    "                ys.append(self.relu(self.bn2[s-1](self.conv2[s-1](xs[s] + ys[-1]))))\n",
    "        out = torch.cat(ys, 1)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.se is not None:\n",
    "            out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da880bf-fc28-42b1-a7f0-054be623e9ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Res2Net(nn.Module):\n",
    "    def __init__(self, layers, num_classes=100, zero_init_residual=False,\n",
    "                 groups=1, width=64, scales=4, se=False, norm_layer=None):\n",
    "        super(Res2Net, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        planes = [int(width * scales * 2 ** i) for i in range(3)]\n",
    "        self.inplanes = planes[0]\n",
    "        self.conv1 = conv3x3(3, planes[0])\n",
    "        self.bn1 = norm_layer(planes[0])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(Res2NetBottleneck, planes[0], layers[0], scales=scales, groups=groups, se=se, norm_layer=norm_layer)\n",
    "        self.layer2 = self._make_layer(Res2NetBottleneck, planes[1], layers[1], stride=2, scales=scales, groups=groups, se=se, norm_layer=norm_layer)\n",
    "        self.layer3 = self._make_layer(Res2NetBottleneck, planes[2], layers[2], stride=2, scales=scales, groups=groups, se=se, norm_layer=norm_layer)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(planes[2] * Res2NetBottleneck.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Res2NetBottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, scales=4, groups=1, se=False, norm_layer=None):\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, downsample, stride=stride, scales=scales, groups=groups, se=se, norm_layer=norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, scales=scales, groups=groups, se=se, norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a74a041f-64bd-4877-90c4-de7729be8e78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "learning_rate=0.01\n",
    "momentum=0.9\n",
    "weight_decay=0.0001\n",
    "batch_size=64\n",
    "epochs=50\n",
    "data_path='./data'\n",
    "model_name='Res2Net50'+'epoch='+str(epochs)\n",
    "print(device)\n",
    "model=Res2Net([3, 3, 3], groups=6, width=24, scales=4).to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80cb8dc-6bd3-46f2-a053-1b595c4dfc06",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainloader,testloader=get_data_loaders(train_batch_size=batch_size,test_batch_size=batch_size,data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a82027-923c-4da2-8a0a-66079b05c481",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_lossa, test_lossa = [], []\n",
    "train_acca, test_acca = [], []\n",
    "train_top5_acca, test_top5_acca = [], []\n",
    "for epoch in range(epochs):\n",
    "    train_loss,train_acc,train_top5_acc=train(model,trainloader,criterion,optimizer,device)\n",
    "    print('epoch:{},'.format(epoch))\n",
    "    test_loss,test_acc,test_top5_acc=test(model,testloader,criterion,device)\n",
    "    print('train_loss:{:.4f},train_acc:{:.4f},train_top5_acc:{:.4f},test_loss:{:.4f},test_acc:{:.4f},test_top5_acc:{:.4f}'.format(train_loss,train_acc,train_top5_acc,test_loss,test_acc,test_top5_acc))\n",
    "    torch.save(model.state_dict(), model_name+'.pth')\n",
    "    train_lossa.append(train_loss)\n",
    "    test_lossa.append(test_loss)\n",
    "    train_acca.append(train_acc)\n",
    "    test_acca.append(test_acc)\n",
    "    train_top5_acca.append(train_top5_acc)\n",
    "    test_top5_acca.append(test_top5_acc)\n",
    "\n",
    "#画图\n",
    "save_plots(train_acca,test_acca,train_lossa,test_lossa,train_top5_acca,test_top5_acca,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aca0f8-f4f8-47d5-af24-bd8bd1fc1f98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}